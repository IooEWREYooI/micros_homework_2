# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

### Решение

#### Выбор облачной системы

Для реализации задачи выберем **Amazon Web Services (AWS)** в качестве облачной платформы. AWS предоставляет широкий спектр сервисов, необходимых для микросервисной архитектуры, имеет высокую надежность, масштабируемость и развитую экосистему интеграций. Это позволит сосредоточиться на разработке бизнес-логики, а не на инфраструктурных вопросах.

#### Система контроля версий Git

В качестве системы контроля версий выберем **GitHub Enterprise** в связке с **GitHub Actions** для CI/CD. GitHub предоставляет:
- Распределенную систему контроля версий Git
- Интеграцию с широким спектром инструментов
- Возможность хранения отдельного репозитория для каждого микросервиса
- Встроенные возможности CI/CD через GitHub Actions

#### Реализация требований

1. **Репозиторий на каждый сервис**: Каждый микросервис будет иметь свой отдельный репозиторий в GitHub для обеспечения независимости разработки и развертывания.

2. **Запуск сборки по событию из системы контроля версий**: GitHub Actions будет автоматически запускать сборку при пуше в определенные ветки (например, main, develop) или при создании pull request.

3. **Запуск сборки по кнопке с указанием параметров**: GitHub Actions поддерживает ручной запуск workflows с возможностью указания параметров через workflow_dispatch.

4. **Возможность привязать настройки к каждой сборке**: Использование GitHub Secrets и Environment Variables для хранения конфигураций, специфичных для каждой сборки.

5. **Возможность создания шаблонов для различных конфигураций сборок**: Создание переиспользуемых workflow templates и composite actions.

6. **Безопасное хранение секретных данных**: GitHub Secrets обеспечивает безопасное хранение и использование паролей, ключей доступа и других конфиденциальных данных.

7. **Несколько конфигураций для сборки из одного репозитория**: Использование различных веток, environment variables и GitHub Environments для различных конфигураций (dev, staging, prod).

8. **Кастомные шаги при сборке**: GitHub Actions позволяет определять кастомные шаги в виде shell-скриптов или переиспользуемых actions.

9. **Собственные докер-образы для сборки проектов**: Использование Amazon ECR (Elastic Container Registry) для хранения собственных Docker-образов.

10. **Возможность развернуть агентов сборки на собственных серверах**: GitHub Actions поддерживает self-hosted runners для выполнения задач на собственной инфраструктуре.

11. **Возможность параллельного запуска нескольких сборок**: GitHub Actions позволяет запускать несколько workflows параллельно, а также использовать стратегии матричной сборки.

12. **Возможность параллельного запуска тестов**: Тесты могут запускаться параллельно в разных jobs или с использованием матричной стратегии.

---

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

### Решение

Для реализации системы логирования выберем стек **ELK (Elasticsearch, Logstash, Kibana)** с дополнением **Filebeat** для сбора логов.

#### Компоненты решения:

1. **Filebeat**: Агент для сбора логов с хостов. Собирает логи из stdout контейнеров и других источников, имеет минимальные требования к приложениям.

2. **Logstash**: Сервис для обработки, фильтрации и трансформации логов перед отправкой в Elasticsearch.

3. **Elasticsearch**: Распределенное хранилище и поисковая система для логов. Обеспечивает гарантированную доставку и хранение логов.

4. **Kibana**: Веб-интерфейс для визуализации, поиска и анализа логов. Предоставляет возможности поиска, фильтрации и создания сохраненных поисков с возможностью предоставления ссылок.

#### Архитектура взаимодействия:

```
Микросервисы (stdout) → Filebeat → Logstash → Elasticsearch ← Kibana
```

#### Обоснование выбора:

- **Сбор логов в центральное хранилище**: Elasticsearch предоставляет распределенное хранение с репликацией
- **Минимальные требования к приложениям**: Filebeat может собирать логи из stdout без изменений в приложениях
- **Гарантированная доставка**: Filebeat обеспечивает надежную доставку с механизмом подтверждения
- **Поиск и фильтрация**: Kibana предоставляет мощные возможности поиска и фильтрации
- **Пользовательский интерфейс**: Kibana предлагает интуитивный веб-интерфейс для разработчиков
- **Сохраненные поиски с ссылками**: Kibana позволяет сохранять поиски и делиться ссылками на них

Альтернативно можно рассмотреть более легковесное решение на базе **Fluentd + Elasticsearch + Kibana**, где Fluentd заменит собой Filebeat и Logstash, что упростит архитектуру.

---

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

### Решение

Для реализации системы мониторинга выберем связку **Prometheus + Grafana**, которая стала индустриальным стандартом для мониторинга в среде контейнеризированных приложений и микросервисов.

#### Компоненты решения:

1. **Prometheus**: Система мониторинга и алертинга с моделью pull-сбора метрик. Хранит данные в виде временных рядов.

2. **Node Exporter**: Экспортер для сбора метрик с хостов (CPU, RAM, HDD, Network).

3. **cAdvisor**: Сбор метрик с Docker-контейнеров (ресурсное потребление каждого сервиса).

4. **Grafana**: Платформа для визуализации метрик с возможностью создания дашбордов и панелей.

5. **Alertmanager**: Система управления алертами (опционально).

#### Архитектура взаимодействия:

```
Хосты/Сервисы → Node Exporter/cAdvisor → Prometheus ← Grafana
```

#### Обоснование выбора:

- **Сбор метрик со всех хостов**: Node Exporter устанавливается на каждый хост для сбора системных метрик
- **Сбор метрик состояния ресурсов хостов**: Node Exporter предоставляет стандартные метрики CPU, RAM, дискового пространства, сети
- **Сбор метрик потребляемых ресурсов для каждого сервиса**: cAdvisor собирает детальную информацию о потреблении ресурсов каждым контейнером
- **Сбор метрик, специфичных для каждого сервиса**: Микросервисы могут экспортировать кастомные метрики в формате Prometheus через endpoint /metrics
- **Пользовательский интерфейс с запросами и агрегацией**: Prometheus предоставляет встроенный интерфейс для запросов, а Grafana - расширенные возможности агрегации
- **Настройка панелей для отслеживания состояния системы**: Grafana позволяет создавать кастомные дашборды и панели для визуализации метрик

Для микросервисной архитектуры Prometheus особенно хорош тем, что:
- Поддерживает service discovery для автоматического обнаружения микросервисов
- Имеет богатую экосистему экспортеров для различных систем
- Обеспечивает высокую производительность при сборе метрик от большого количества сервисов
- Позволяет определять алерты на основе правил

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.